{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "##Seaborn for fancy plots. \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams[\"figure.figsize\"] = (8,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3950 Assignment 1: Part 2\n",
    "\n",
    "Sample solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Muh Name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "      <th>var_200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  var_1  var_2  var_3  var_4  var_5  var_6  var_7  var_8  var_9  ...  \\\n",
       "0       0  0.660  0.106  0.434  0.387  0.903  0.661  0.158  0.291  0.210  ...   \n",
       "1       1  0.844  0.813  0.030  0.939  0.721  0.287  0.539  0.874  0.787  ...   \n",
       "2       0  0.560  0.567  0.568  0.434  0.414  0.180  0.448  0.888  0.023  ...   \n",
       "3       0  0.681  0.245  0.909  0.785  0.738  0.570  0.692  0.411  0.182  ...   \n",
       "4       0  0.846  0.431  0.805  0.237  0.465  0.642  0.219  0.102  0.795  ...   \n",
       "\n",
       "   var_191  var_192  var_193  var_194  var_195  var_196  var_197  var_198  \\\n",
       "0    0.015    0.377    0.479    0.050    0.395    0.123    0.833    0.461   \n",
       "1    0.112    0.048    0.088    0.860    0.560    0.346    0.511    0.883   \n",
       "2    0.874    0.236    0.599    0.602    0.005    0.493    0.122    0.395   \n",
       "3    0.219    0.691    0.261    0.031    0.968    0.353    0.798    0.104   \n",
       "4    0.704    0.242    0.089    0.605    0.577    0.043    0.686    0.070   \n",
       "\n",
       "   var_199  var_200  \n",
       "0    0.990    0.105  \n",
       "1    0.858    0.599  \n",
       "2    0.782    0.943  \n",
       "3    0.944    0.090  \n",
       "4    0.666    0.572  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"training.csv\")\n",
    "df = df.drop(columns={\"id\"})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a trial run to see what a default forrest looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.6133333333333333\n",
      "Avg Depth: 8.23\n"
     ]
    }
   ],
   "source": [
    "#model\n",
    "y_trial = np.array(df[\"target\"]).reshape(-1,1)\n",
    "X_trial = np.array(df.drop(columns={\"target\"}))\n",
    "X_trainT, X_testT, y_trainT, y_testT = train_test_split(X_trial, y_trial.ravel(), test_size=.3)\n",
    "\n",
    "trial_forrest = RandomForestClassifier()\n",
    "trial_pipe = [('scale', StandardScaler()),('forest', trial_forrest) ]\n",
    "pipe = Pipeline(trial_pipe)\n",
    "# The pipeline can be used as any other estimator\n",
    "# and avoids leaking the test set into the train set\n",
    "pipe.fit(X_trainT, y_trainT)\n",
    "print(\"Score:\", pipe.score(X_testT, y_testT))\n",
    "trial_depths = [estimator.tree_.max_depth for estimator in trial_forrest.estimators_]\n",
    "print(\"Avg Depth:\", np.mean(trial_depths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model using grid search to tune HPs. The training set is very small, so calculation of many options should be pretty fast. \n",
    "\n",
    "I'm going to scale the data, but I suspect that will not be a massive impact. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Pipeline with Scaling. \n",
    "scaler = StandardScaler()\n",
    "estimator = RandomForestClassifier(n_jobs=-1, verbose=0)\n",
    "pipe = Pipeline(steps=[(\"scaler\", scaler), (\"forest\", estimator)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_trial, y_trial.ravel(), test_size=.3)\n",
    "\n",
    "rf_para = {'forest__min_samples_split':[3,4,5,6],\n",
    "            #'forest__criterion':[\"gini\",\"entropy\"],\n",
    "            'forest__max_depth':[4,5,6,7],\n",
    "            'forest__n_estimators':[200],\n",
    "            'forest__max_samples':[.4, .5, .6, .7],\n",
    "            'forest__ccp_alpha':[.000005,.00001,.00005,.0001,.0005,.001]}\n",
    " \n",
    "clf = GridSearchCV(pipe, param_grid=rf_para, cv=5, n_jobs=-1) \n",
    "clf.fit(X_train, y_train.ravel())\n",
    "best = clf.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.56\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(ccp_alpha=0.0005, max_depth=5,\n",
      "                                        max_samples=0.7, min_samples_split=3,\n",
      "                                        n_estimators=200, n_jobs=-1))])\n"
     ]
    }
   ],
   "source": [
    "print(best.score(X_test, y_test))\n",
    "print(best)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain Model\n",
    "\n",
    "We can use all the data to train the model, now that we've determined the best \"settings\". These are the hyperparameters that we found to be the best in the grid search above. Because there is random variation, the exact values may vary a bit - if we wanted them to be constant, we'd need to set the random seed above so things don't change from run to run. Since this uses all the data, we should expect that it is an improvement over the model we got above, that was trained with 70% of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2 = Pipeline(steps=[(\"scaler\", StandardScaler()), (\"forest\", RandomForestClassifier(n_jobs=-1, verbose=0, ccp_alpha=.0005, max_depth=5, max_samples=.7, min_samples_split=3, n_estimators=200))])\n",
    "best = pipe2.fit(X_trial, y_trial.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "Please leave the stuff below as-is in your file. \n",
    "\n",
    "This will take your best model and score it with the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.645103640978653\n",
      "0.6445569620253164\n",
      "Muh Name 0.6448303015019847\n"
     ]
    }
   ],
   "source": [
    "#Load Test Data\n",
    "test_df = pd.read_csv(\"testing.csv\")\n",
    "test_df = test_df.drop(columns={\"id\"})\n",
    "#Create tests and score\n",
    "test_y = np.array(test_df[\"target\"]).reshape(-1,1)\n",
    "test_X = np.array(test_df.drop(columns={\"target\"}))\n",
    "\n",
    "preds = best.predict(test_X)\n",
    "\n",
    "roc_score = roc_auc_score(test_y, preds)\n",
    "acc_score = accuracy_score(test_y, preds)\n",
    "\n",
    "print(roc_score)\n",
    "print(acc_score)\n",
    "print(name, np.mean([roc_score, acc_score]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d722d3adfa415172c1f5238b519fb86b488acdae450fd691ab06c09f4ca9173"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ml3950': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 08:50:36) \n[Clang 10.0.0 ]"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
